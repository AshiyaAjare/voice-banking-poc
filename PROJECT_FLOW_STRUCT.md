# Voice-Print Backend: Implementation Flow & Structure

This document provides a detailed overview of the currently implemented flow and folder structure for the `voice-print-backend` project.

---

## üìÇ Project Folder Structure

The project follows a modular structure separated into API layers, core logic, and specialized services.

```text
voice-print-backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ v1/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ voice.py          # FastAPI Router: Primary API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crypto/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ xor_cipher.py     # XOR-based audio encryption/decryption
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Pydantic schemas and data models
‚îÇ   ‚îú‚îÄ‚îÄ services/                 # Business Logic Layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ accent/               # NEW: Multi-language & accent logic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ accent_profile_service.py   # Orchestrator for language buckets
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enrollment_policy.py        # Rules for language enrollment
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ verification_policy.py      # Decision logic for accent-matching
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voice_service.py      # Core voice enrollment & verification
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speaker_model.py      # Wrapper for ECAPA-TDNN & X-Vector models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speaker_model_provider.py # Factory for selecting models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audio_validator.py    # Voice activity detection & quality checks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ embedding_utils.py    # Math/Tensor helpers for centroids
‚îÇ   ‚îî‚îÄ‚îÄ main.py                   # FastAPI Application initialization
‚îú‚îÄ‚îÄ storage/                      # Persistence Layer
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/               # Finalized speaker profiles (.pt & profile.json)
‚îÇ   ‚îî‚îÄ‚îÄ pending/                  # Temporary storage for partially enrolled samples
‚îú‚îÄ‚îÄ pretrained_models/            # Local storage for model weights
‚îî‚îÄ‚îÄ audio/                        # Temporary directory for audio processing
```

---

## üîÑ Implementation Flow

The backend implements a sophisticated, multi-stage process for securing and processing voice data.

### 1. üõ°Ô∏è Audio Security (XOR Cipher)
To protect voice data in transit, the system implements a symmetric encryption layer:
- **Frontend**: Encrypts raw audio bytes using an `XORCipher` with a shared secret key.
- **Backend**: Every voice-related endpoint (`/enroll/sample`, `/accent/verify`, etc.) decrypts the incoming `UploadFile` bytes at the API boundary before any processing occurs.

### 2. üë• Accent-Aware Enrollment Flow
The new flow supports "buckets" for different languages/accents to improve accuracy for multilingual users.

```mermaid
sequenceDiagram
    participant FE as Frontend
    participant API as voice.py
    participant APS as AccentProfileService
    participant VS as VoiceService
    participant SM as SpeakerModel

    FE->>API: POST /enroll/start (languages)
    API->>APS: Initialize Profile
    APS-->>FE: Session ID / Requirements

    loop For each language (Primary, Secondary, Optional)
        loop Samples 1..N
            FE->>API: POST /enroll/sample (audio + lang)
            API->>API: Decrypt Audio
            API->>APS: Process Sample
            APS->>VS: Enroll Scoped User (user_id:lang)
            VS->>SM: Extract Dual Embeddings
            VS->>VS: Save Pending Sample
            Note right of VS: Centroid created after N samples
            VS-->>FE: Progress Status
        end
    end
```

**Key Features:**
- **Language Buckets**: Each language is enrolled into its own "scoped" profile (e.g., `user_123:hi-IN`).
- **Centroid Calculation**: Multiple samples (default: 3) are required for each bucket. These are combined into a robust "centroid" embedding.
- **Dual Model Enrollment**: Every sample is processed by two models: **ECAPA-TDNN** (Primary) and **X-Vector** (Secondary).

### 3. ‚úÖ Accent-Aware Verification Flow
Verification uses "strategies" to handle the multiple language buckets enrolled for a user.

- **Strategies**:
    - `best_of_all`: Tries the input voice against all enrolled language buckets and returns the best match.
    - `accent_matched`: Uses advisory accent detection to pick the most likely bucket first.
    - `declared_language_fallback`: Tries buckets in order of priority (Primary ‚Üí Secondary ‚Üí Optional).

- **Decision Policy (Dual Scoring)**:
    - The system calculates similarity scores for both models.
    - A comparison is made against a configurable `SIMILARITY_THRESHOLD`.
    - Scores are "fused" if both models are available to increase confidence.

### 4. üóÑÔ∏è Storage Mechanics
- **Finalized Profiles**: Stored as `.pt` (PyTorch) files containing primary and secondary centroids, metadata (timestamps), and versioning.
- **Profile Metadata**: `profile.json` tracks the high-level user preferences and enrollment progress.
- **Pending Samples**: Partial enrollments are stored in a dedicated `pending/` directory until the requirement is met, at which point they are combined and cleaned up.

### 5. üåç Language Identification (LID)
The system integrates **SpeechBrain LID** to detect the spoken language from raw audio.
- **Control Plane Only**: LID is used for routing to language buckets and ordering fallback strategies.
- **Strict Advisory**: It never affects the speaker embeddings or similarity scores directly.

---

## üõ†Ô∏è Technological Stack

- **Framework**: FastAPI (Asynchronous Python)
- **Deep Learning**: PyTorch + Torchaudio
- **Models**: 
    - **Speaker Identity**: ECAPA-TDNN & X-Vector (SpeechBrain)
    - **Language ID**: VoxLingua107 LID-ECAPA (SpeechBrain)
    - **VAD**: Silero VAD
- **Security**: XOR-based byte stream encryption.
- **Logic**: Accent-aware policies for custom enrollment and verification thresholds.
